-- *****Реализация Баз Данных SQL Server 2008*****

Начало, подводные камни типов данных(не естественных(суррогатный ключ)). Identity.

@@TRANCOUNT - как глубоко закопались в танзакции

-- Харенение строки
1. Сначала хранятся строки постоянной длины
2. Потом поля типа бит для каждого поля в таблице где может быть NULL и там либо да, либо нет. Поэтому NULL Это не пустое значение
3. Потом строки переменной длины
	1. Сначала хранятся поля с цифрой размерностей строк переменной длины
	2. Потом сами значения этих строк

-- Транзакции (SET TRANSACTION ISOLATION LEVEL):
1. READ UNCOMMITTED (грязное чтение)
2. READ COMMITTED (неповторяемое чтение. сначала селекта одни данные, потом подтвердилось изменение и появились другие данные в одной
   транзакции. НИКОГДА НЕ ИСПОЛЬЗУЮТ В ОТЧЁТАХ). Писатели блокируют читателей
3. REPEATABLE READ (фантомные записи, при инсерте появляются новые записи)(будет блокировать эти строки даже для записи).
   Читатели блокируют писателей.
4. SERIALIZABLE (полная блокировка)
5. Snapshot (читающие транзакции получают предыдущую копию данных). Включить ALTER DATABASE Database SET ALLOW_SNAPSHOT_ISOLATION ON;
SET TRANSACTION ISOLATION LEVEL SNAPSHOT
- Пример: 
SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;


EXECUTE sp_lock - показывает блокировки (1:38 в 8 видео)
S - разделяемая блокировка
X - экслюзивная блокировка
GRAND - наложено
WAIT - ожидает

ПЕССИМИСТ(проблемы):
1. Ожидание блокировок (если ситуация со счётчиками ухудшается, необходимо сообщить разработчику: Average Latch Wait Time, Latchs Waits, Total Latch Wait Time)
2. Дедлоки, взаимная блокировка (Сервер умеет их обнаруживать и решать вопрос отменой одной из транзакций). DEADLOCK - в профайлере, в разделе Locks -> Deadlock graph (показывает графически где deadlock)

ПЕССИМИСТ(плюс):
1. ПРЕДСКАЗУЕМОСТЬ

SELECT ... WITH NOLOCK - лучше использовать для временного перехода в более слабый режим блокировок или нет другого выхода

Советы пессимисту:
1. Укорачивать транзакции (см. триггеры -> ServiceBroker)
2. Понижать режим изоляции
3. Запускать все транзакции в одном направлении
4. SET DEADLOCK_PRIORITY
5. Если дедлоков не избежать, нужно операцию, что его вызывает, ставить вначало транзакции, чтобы серверу не пришлось откатывать всю транзакцию.
6. Подменить маркер (использовать крайне редко). 9 видео, 22 минута
7. Если ничего не помогло - стань оптимистом
8. Перехватывать 1205 -> перезапустить транзакцию

ОПТИМИСТ (обычно реализуется на стороне приложения, всё работает через cache приложения)(проблема в том, что он использует сильно tempDB, если используется этот режим, то лучше положить tempDB на отдельный, большой диск)(изначально этот режим отключён)(ПЛЮС - ПОЛУЧИТЬ ОТСУТСВИЕ ГРЯЗНОГО ЧТЕНИЕ И ОТСУТСВИЕ БЛОКИРОВОК, использовать именно тогда, например отчёты):
1. С 2005 версии SHNAPSHOT. 9 видео, 38 минута
2. READ COMMITTED SHNAPSHOT. Отличие в том, что каждый новый селект здесь будет брать новую информацию с БД. Большая нагрузка на диск

Проблемы оптимиста:
1. Нагрузка на tempdb
2. UPDATE CONFLICT

Поведение:
1. Перехватывать 3960 -> перезапустить транзакцию
2. По возможности переключаться в READ UNCOMMITTED (WITH NOLOCK)

-- NOLOCK/Read uncommitted
	- Грязное чтение
	- Возможность прочитать одну строку несколько раз
	- Возможность получить не только больше, но и меньше строк
	- Ошибка чтения данные при их перемещении
	- Так как NOLOCK требует блокировку стабильности схемы (Sch-S), то любые её модификации приводят к блокировкам. Например создание индекса заблокирует чтение с помощью NOLOCK
	- Так же NOLOCK накладывает блокировки на METADATA

sp_who и sp_who2 - кто владеет транзакциями

DatePart(hour,GetDate()) - для работы с более точным временем
CURRENT_TIMESTAMP -- Аналог GetDate()

SELECT @@DBTS - номер последней операции на сервере

Второй урок особенности CHECK

dateadd()
datediff()
Computed Colump Specification - вычисляемые столбцы

функция If Udate(поле) - если обновляется даное поле, то журналируем.

SET XACT_ABORT ON - сказать серверу что операция не делима и надо рушить всю конструкцию, а не неверный оператор

Оптимистический режим позволяет сделать отсутсвие блокировок и грязного чтения (лучше только в этом режиме и использовать)

Оптимистический режим(недостатки):
1. Большая нагрузка на диск.(tempdb лучше получить на отдельный диск)
2. UPDATE CONFLICT

SELECT *
FROM   Customers
FOR XML RAW ('Clients') , ROOT ('Customer'), ELEMENTS
RAW ('Clients')--Строки будут элементами, стобцы атрибутами
ROOT ('Customer') -- Корневой элемент

режим AUTO (вместо RAW)разбивает на уровень вложенности ориентируясь на порядок в JOIN.
AUTO и RAW не управляются.

Режим PATH

Для работы с XML и реляционными данными нужно использовать следующую конструкцию, чтобы обращаться к функциям sql

DECLARE @Editor varchar(100) = Current_User

SET @Event.modify('insert <Change Editor="{sql:variable("@Editor")}" /> into /Update[1]'

-- Возможность внесений изменений, требующих пересоздание таблицы
- Сервис>Параметры>Конструкторы>Галочка "Запретить сохранение изменений, требующих повторного создания таблицы"

-- Хранилища/Data Warehousing	
	- Основная функция - хранение большого объёма информации, которая обычно используется для чтения
	- Логический дизайн
		1. Звезда (Таблица фактов, с большим количеством таблиц измерений)
		2. Снежинка (К измерениям добавляются свои измерения)
		3. Избегайте длинных строк, большого объёма двоичных данных или колонок типа uniqueidentifier в таблице
		   фактов
		4. Для измерений - целочисленные типы
		5. Избегайте указания большой точности
	- Физический дизайн
		1. Не обязательно отражать логическую сущность
		2. Реализуйте для оптимальной производительности
		3. Выбор расположения файлов и файловых группы
		4. Выбор оптимального секционирования таблиц
		5. Использование постраничного сжатия для таблиц фактов (PAGE)
	- Конфигурирование файловых групп
		1. Каждый файл > отдельный диск
		2. Все файлы > одна группа
		3. Все таблицы > в эту файлову группу
	- Избегайте использования более 32 файлов в одной файловой группе
	- Дизайн индексов
		- Таблица фактов:
			1. Кластерный индекс на DateKey (временные интервалы)
			2. Если Таблица больше 50 Гб, секционировать по DateKey
			3. DateKey в формате YYYYMMDD
			4. Не использовать никаких доп. индексов
		- Таблица измерений
			1. Для маленький таблиц можно не использовать индексы, кромо тех, что обеспечивают целостность данных
			2. Для больших таблиц - для ускорения наиболее типичных фильтров
	- Загрузка данных
		1. Можем загрузить кластерный индекс напрямую (BULK INSERT). Требования
			- Полный набор данных должен помещаться в память для сотировки
			- Все данные загружаются в едиснтвенной транзакции с BATCHSIZE = 0. Это предотвращает излишнюю
			  фрагментацию и дробление страниц
			- Загрузка последовательная (1 поток), но мы достигаем отсутсвия фрагментации
		2. Можем загрузить кластерный индекс через доп. таблицу. То же можем использовать BULK INSERT:
			- Загрузка параллельно
			- Ненулевой размер BATCHSIZE (подбирается, чтобы не было сортировки в TEMPDB)
			- Далее берём эту таблицы в единственный INSERT...SELECT с MAXDOP = 1 для предотвращения
			  фрагментации
			- Это даёт более высокую скорость загрузки
	- Для больших объёмов данных
		1. Разбиваем данные по файлам по дате
		2. Загружаем в несколько промежуточных таблиц одновременно
		3. Загружаем каждую из таблиц как на рекомендации выше
		4. Последовательно переключаем секции между промежуточными и основной таблицей
	- Для улучшения производительности
		- В версии 2008
			1. Сжатие при резервном копировании
			2. Оптимизация запросов типа "звезда" (Star join)
			3. Оптимизация запросов типа few outer rows
			4. Выровненные по секциям индексированные представления (partition aligned indexed views)
		- Все версии
			1. Использование сводных таблиц и индексированных представлений для запросов агрегатов
			2. Использовать целочисленные типы данных для ключевых колонок измерений
		- 2008 R2
			1. Поддержка 256 аппаратных потоков
			2. Реализация сжатия Unicode
	- Сжатие данных
		1. Постраничное
			- В среднем в 3х(иногда от 2 до 8)
			- Для небольших таблиц это не выгодно
			- Снимает нагрузку с диска
		2. По строкам
	- Оптимизация запросов типа "звезда"
	- Индексированные представления
	- Облако/Cloud/Asure
		- Проблема облака - драйвер связи дисков и операционной системы, он имеет пропускную способность 200 Мб/с
		- Прочитать способы загрузки данных в хранилище - data loading performance guide
		- Включить блокировку страниц в памяти
		- И там же Perform volume maintance tasks
		- Так же сделать приращение файла большими порциями
		- Разбиение файловой грыппы на множество файлов, которые будут лежать на разных дисках (file страйпинг)
		- Можно использовать Windows Storage Spaces, особенно для лога файлов, а для файла данных можно использовать страйпинг или то же самое
		- Для файлов лога (нагрузка типа запись) лучше объём пакета 64к, для данных 256к
		- Backup/Respore через URL - самый быстрый способ
		-- Правила облака
			1. Меньшие размеры батчей при копировании (10к-15к)
			2. Логика повтора
			3. Сетевые задержки высоки
			4. Параллельная загрузка - ключ к успеху
			5. Читаем гайды: SSIS for Hybird Data Movement и SSIS Performance and operational guide
			6. Flat File на диске даёт максимально 60 Мб/с
			7. Изменяя что-то в системе надо смотреть не как хороши стали задержки, а на сколько это изменилось с прошлого раза
			8. Компрессию Heap(кучи), лучше не использовать, так как сильно увеличивается время загрузки данных. Можно сначала загрузить, потом компрессировать. Если Heap заменить на кластерный индекс, то время увеличится примерно с 1:05 часа до 1:20

-- Обозначения жёстких дисков
A 5400 RPM (многодисковый)
B 7200 RPM
C 10,000 RPM
D 4500 RPM
E 5400 RPM (однодисковый)
F 10,000 RPM c 2 Мб кэша
G 10,000 RPM с 8 Мб кэша
H 10,000 RPM с 4 Мб кэша
J 7200 RPM с 8 Мб кэша
L 7200 RPM (Fluid Dynamic Bearings)
M 5400 RPM (Fluid Dynamic Bearings)
P 7200 RPM with 8 MB cache (Fluid Dynamic Bearings)

-- Автономные базы данных (Новая возможность в 2012 версии)
	- База содержит в себе все настройки, не должно быть никакой связи с сервером, но пока это
	  реализовано частично.
	- Благодаря автономным базам аутентификация производится не на сервере, а в базе
	- Как это сделать:
		1. Разрешить автономные Базы Данных (Свойства сервера>Дополнительно>Разрешить автономные базы)
		2. Разрешить базе быть автономной (Свойство базы>Опции>4 поле сверху)
		3. Создать пользователя в базе с параметром (user type) автономного пользователя
		4. При подключении с помощью такого юзера, надо в настройках указать базу, где такой юзер
		
		- Проблемы:
			1. Логины сервера, это не все пользователи. Они ещё будут храниться в Базах

	- Можно мигрировать базу с пользователями в автономный режим:
		1. Разрешить автономные Базы Данных (Свойства сервера>Дополнительно>Разрешить автономные базы)
		2. Разрешить базе быть автономной (Свойство базы>Опции>4 поле сверху)
		3. EXECUTE sp_Migrate_User_to_Contained (логин блокируетсян а сервере, а пользователь мигрирует в базу)
		4. Проверка всех ли пользователей удалось перенести - Select * FROM sys.DM_DB_Uncontained_Entities
		   (покажет все ссылки, которые связывает базу с сервером, в идеале оно должно быть пустым)
	- Плюсы:
		1. Пользователей не надо тащить на новый сервер
		2. Не нужно делать какую-то настройку на весь сервер, чтобы она работала только для этой базы
	- Минусы:
		1. Нет единого списка имён входа
		2. Парольные хэши попадают в резервную копию
	
-- Колоночные индексы (SQL Server 2012)
- Доступна в Standart версии
- Пока реализован только некластерный колоночный индекс
- Здесь работает встроенное сжатие колоночного индекса, поэтому занимает меньше место
- В типе индекса выбрать Columnstore index
- Может быть только один, но можно включить множество столбцов и то по чему будем группировать и
  что будем агрегировать, всё сваливаем в кучу
- Порядок, перечисления столбцов в таком индексе, значения не имеет
- Это всегда Scan в плане выполнения, но это означает не полный перебор. Метаданные в 8кб страницах
  позволяет исключить лишние данные
- Не требует захода в кластерный индекс
- Перестраивается относительно быстро
- Нельзя создавать по вычисляемым столбцам
- Нельзя создавать по вьюшкам
- Не поддерживается для фильтрованных индексов
- Не поддерживается в индексированных представлениях
- Не все тип данных (decimal с выской точностью)
- Есть проблемы со статистикой
- 8кб страница содержит всегда данные одной колонки, данные не сортированы, оптимизируем для скнаирования
  и фильрации. При извлечении данных нам надо поднять в память всего одну страницу, без лишних данных
- Большая степень сжатия
- Майкрософт рекомендует делать столбцовый индекс строить по всем столбцам
- Столбцовый индекс работает не в памяти, а на диске
- Наиболее эффективные типы данных - целочисленные, decimal менее 18
- Все столбцы упорядочиваются независимо

- Где применять:
	1. В хранилищах
	2. Отчёты с агрегаций
	3. Отчёты с группировкой
	4. Запросы на чтения на больших объёмах, когда используется схема звезда
	5. Скользящее окно
	6. Практически всегда на таблице фактов
	7. Иногда на таблице измерений, только на очень больших таблицах
- Минусы:
	1. Таблица сразу переходит в ReadOnly. Есть 2 способа как это решить:
		- Перед изменением данных отключать его, загрузить данные, а потом включать
		- Использовать переключение секций: сначала делаем выгрузку в отдельную таблицу, после
		  переключаем секцию из неё, в боевую таблицу
	2. Не все типы данных можно поместить в колоночный индекс. Можно обойти это созданием сурогатных ключей,
	   представлением строковых данных в виде челочисленных
	3. Время построение такого индекса примерно в 1,5-3 раза больше чем некластерного и требует много памяти.
		Решения:
			- Увеличение количества памяти
			- Увеличение гранта на память от памяти SQL Server. Изначально это 25%
	4. Если на сервере будет недостаточно памяти, то даже если оптимизатор решил использовать колоночный
	  индекс, то он всё равно переключится на обычный и при этом такой запрос будет медленней класического
	5. Не стоит использовать на точечных запросах
	6. Узким местом может стать время передачи данных клиенту (сеть)
	7. Аккуратней надо использовать Foreign Key
	8. Обилие других индексов может сподвигнуть оптимизатор выбрать неправильный индекс, если колоночный
	   быстрее в любом случае, то надо использовать подсказку оптимизатору
	9. Запросы с большим количеством строк и мы используем обработку этих строк, лучше выполнять на
	   обычных индексах
	10. Автоматически не создаёт, поэтому необходимо обновлять её самому или даже создавать самому
	11. Если предикат содержит инстукции OR, то генерируется менее эффективный план запроса
	12. Для UNION ALL создаёт неэффективный план
	13. Плохая производительность с операторами IF EXISTS,IN, NOT IN, OUTER JOIN
	
-- Таблицы в памяти
- Объём таблиц в памяти не должен превышать объём допустимый для SQL Server
- запись в данную таблицу будет производиться в обычном режиме, то есть на общем основании.
  Но, при этом второе, и каждое последующее чтение страниц таблицы будет осуществляться не с диска, а из буфера в памяти MS-SQL сервера.
	   
-- Файловые таблицы
- Как храним документы большого объёма, который не хотим хранить в базе и обратабывать:
1. Image, varbinary(Max). Загружать в базу в бинарном виде
	- Храним всё в базе
	- В 1 ячейке может быть не можем хранить более 2 Гб
2. Ссылки на файл
	- Низкая стоимость хранения
	- Нет ссылочной целостности
	- Нет транзакционной целостности
	- Сложное резервное копирование
3. FileStream, FileTable
	- FileStream:
		- SQL Server 2008
		- Удаляя базу, мы удаляем все файлы, что к ней относятся
		- В бэкапе хранятся все файлы
		Недостатки:
			- Не можем найти файл, который относится к конкретной строке через файловую систему, но можно написать функцию/программу, которая это сделает
			- Однострочная ссылочка целостность. Со стороны базы. Если удалим файл, строка в базе не исчезнет. При этом если удалим
			  файл через файловую систему, база нарушит целостность
			- Неудобный достук со стороный файловой системы
	- FileTable
		- SQL Server 2012
		- Надстройка над FileStream
		- Удобная работа с именем файла
		- Двусторонняя ссылочная целостность
		Недостатки:
			- Эффективен, если мы работаем с документами большого размера, если документов много и они маленькие, то мы можем
			  не получить преимущества
			- Требует SQL Server 2012
		
		
-- FileStream
- Может резервировать только таблицу, для этого резервируем нужные файловые группы
- Нельзя читать файлы в режиме отображения в память (так работают некоторые приложения)
1. Включить FileSteam (в настройках Configuration Manager > Экземпляр сервера > В настройках ключить FileSteam, если хотим работать
   не только со стороны SQL, а ещё и со стороны файловой системы, то вкл вторую галочку, третья - удалённый доступ других серверов).
   При этом создаётся общая папка.
2. Свойства в SSMS > Свойства сервера > Advanced > активировать FileStream Access Level
3. Настроить БД
	- Нужно создать спец. файловую группу (нижний список в свойствах базы). Они ничем не отличаются от обычный фаловых групп
	- Включить хотя бы 1 файл в группу. Такой файл, файлом не является, это каталог, указать сможем только логическое имя.
4. Создать файловую таблицу
	- Надо сделать хотя бы 1 поле varbinary(Max) FILESTREAM
	- Надо добавить спец. столбец, который похож будет на первичный ключ(ID uniqueidentifier NOT NULL ROWGUIDCOL UNIQUE)
	- ROWGUIDCOL - позволяет обращаться к столбцу, не зная его имени, может быть только 1
	- Можем файлово хранить только varbinary(MAX)
	CREATE TABLE fs
	(
		[Id] [uniqueidentifier] ROWGUIDCOL NOT NULL UNIQUE, 
		[SerialNumber] INTEGER UNIQUE,
		[Chart] VARBINARY(MAX) FILESTREAM NULL
	)
5. Чтобы вставить данные, в поле varbinary(MAX), всё что вставляем, надо преобразовывать к данному типу
6. Чтобы выбрать данные надо поле varbinary(MAX) обратно преобразовать в нужный формат
7. Файлы храняться на файловой системе в непонятном формате, хотя я могу открыть данные блокнотом
8. 	Проверка на вставку данных
	INSERT INTO fs
    VALUES (newid (), 2, 
      CAST ('' as varbinary(max)));

-- FileTable
- Надстройка над FileStream
- Индексы уже настроены и обычно нет смысла их менять
- Структура уже задана и похожа на структуру файловой системы
- Так как это надстройка, то в папке FileStream всё равно будут создаваться непонятные файлы, но мы можем работать через шару
- Можем в шаре создавать файлы/папки и будут появляться строки в базе и наоборот. Удаление работает так же
- Содержимое хранится в стоблце file_stream
- Может резервировать только таблицу, для этого резервируем нужные файловые группы
- Нельзя читать файлы в режиме отображения в память (так работают некоторые приложения)
1. Включить FileSteam на уровне сервера
2. Включить FileSteam на уровне базы
3. Настроить БД
4. Теперь можно получать доступ к базе через шару, но для этого в настройках базы указать FileStream Directory Name,
   внутри этой папке, для каждой таблицы создаётся своя папка
5. В SSMS теперь отдельная ветка - FileTables
6. Создаём таблицу. Здесь не указываем структуру таблицы, структура за ранее известна.
	CREATE TABLE MyTable as FILETABLE
	WITH
	(
		FILETABLE_DIRECTORY = 'Имя что указали в FileStream Directory Name'
	)

-- Запуск командной строки из SQL
USE master
EXEC master.dbo.sp_configure 'show advanced options', 1
RECONFIGURE
EXEC master.dbo.sp_configure 'xp_cmdshell', 1
RECONFIGURE
GO

xp_cmdshell

-- AlwaysOn
- Построена на старой технологии. Накатывание журналов в реальном времени (Availibel Group), это не репликация
- Накатывание до 4 Резервных серверов (2 с синхронной и 2 с ассинхронной, либо 1 и 1, либо 2 и 2)
- Резервные сервера могут принимать нагрузку на чтение (настраивается какую нагрузку можем принимать), а не через мирроринг снэпшоты или репликации,
  как это было ранее. Нет балансировки нагрузки, делается на уровне приложения
- Встроенное управление
- Нагрузка на Secondary может отличаться от нагрузки на Primary и возможно придётся создавать доп. статистику для Secondary на Primary
  или создаём временную на Secondary, но тогда доп нагрузка на tempdb
- Поддержка кластеров в разных подсетях
- Можно использовать в работе кластерный сервер
- Более расширенная диагностика
- Защита на уровне БД - Availibel Group
- Единое виртуально имя
- Системные базы на сетевых шарах
- Поддержка старой репликации
- Резервное копирование на резервном сервере отмечается и на основном. На резервном Copy-only и Backup журнала
- Соединение настраивается через endpoints
- Канал сжимается и шифрование применяется
- Появился Recovery Anvizer, анализирует все сервера, а потом позволяет восстановить на нужный момент времени. При этом все
  сервера должны быть в одной временной зоне
- На момент сбоя, при переносе Primary на другой сервер, приложению нужно будет переподключиться, так как коннекшн теряется

-- Как работает кэш
- Кэшируются планы
- В память заносятся данные, которые поднимаются с диска
- Кэшируютя процедуры

-- Память
- Поддержку подсоединений клиентов
- Открытых баз данных
- Открытых таблиц
- Блокировок таблиц
 
 -- Статистика таблицы
 - Статистика отображает не реальные данные, а с запаздыванием, потому что очень дорого держать актуальные данные
 - Может формироваться не по всей таблице, а только по её части
 - Есть определённый триггер на автоматическое обновление статистики, он срабатывает при 20% изменении данных 
  (на Sql Server 2012 процент другой). Может получиться ситуация, когда % изменённых данных не более 10 и мы
  получим плохую статистику
 - Любое обновление статистики приводит к рекомпиляции планов
 - Rebuild Index приводит к перестроению статистики по этому индексу с опцией Full Scan
 - Reoganize Index не приводит к обновлению статистики
 - Ссылки:
	1. www.sqlcmd.ru/density-selectivity-cardinality-part01.html
	2. sqlblog.com/blogs/elisabeth_redei/archive/2009/03/01/lies-damned-lies-and-statistics-part-i.aspx
	3. msdn.microsoft.com/en-us/library/ms190397.aspx
	4. www.sqlservercentral.com/articles/strairway+series/72446
	5. www.simple-talk.com/sql/sql-training/questions-about-sql-server-distribution-statistics
	6. www.simple-talk.com/sql/t-sql-programming/13-things-you-should-know-about-statistics-and-the-query-optimizer
 
 - Путь запроса:
 1. Синтаксическая проверка
 2. Привязка имён таблиц/столбцов которые мы написали, к физическим объектам
 3. Логическое дерево запроса передаётся на оптимизацию
 4. Формируется план запроса, который исполняется и возвращается нам
 
 - Что влияет на оптимизатор (3 шаг выше)
 1. Подсказки оптимизатору
 2. Индексы
 3. Конфигурация
 4. Количество процессоров
 5. Стастистика
 
 - Что хранится в статистике
 1. Гистограмма
 2. Плотность
 
 - Зачем нужна статистика
 1. Производительность
 2. Стабильность
 
 - Просмотр статистики
 sys.stats
 sys.stats_columns
 DBCC SHOW_STATISTICS
 
 - Опции базы данных данных
 1. Автообновление статистики
 2. Автоматическое создание статистики
 3. Ассинхронное автоматическое обновление статистики (не будет выполнять обновление статистики сразу, а будет делать
    это в backgroun. Возникает риск того, что данный запрос будет выполнен с неактцальной статистикой)
 
 - На что влияет статистика
 1. Выбор выборки метода данных (Scan и Seek)
 
 - Советы
 1. Статистика по большим полям может создаваться долго и при автоматическом обновлении может вызывать большие задержки
 2. Положиться на автоматическое обновление и что-то самим обновлять
 
 - Когда обновлять статистику
 1. При Bulk-insrert обновлять статистику
 2. Когда требуется большая точность
 3. Если статистику создаём по нескольким колонкам и фильтрованная статистика. Тут надо обязательно самому её обновлять
 
 - Наблюдение за автообновления статистики
 1. Profiler > Auto Stats (группа Perfomace)
 2. В Sql Server 2012, XEStats auto_stats (extendits evets)
 3. В SQL 2012 XEvents, channel = debug, event = inaccurate_cardinality_estimate (когда идёт большое расхождение
    между ожидаемым и реальными строками в плане выполнения)
 
 - Порядок обновления
 1. Сначала статистика, потом индексы
 2. Сначала индексы, потом статистика. Перестроение индексов выполняется с обновление статистики с FULL SCAN и
    если потом перестроить статистику с меньшей выборкой, то мы не только проделаем двойную работу, но и ухудшим статистику
	
- Когда оптимизатор может строить неправильный план
1. Передаём параметр в запрос
	- Решение:
		- Создать процедуру и параметр передавать в неё. Происходит Parameter Sniffing
		- Не надо изменять параметр внутри хранимой процедуры (так как оптимизатор будет использовать значение,
		которое мы передали в процедуру)
2. Используем подзапрос
3. Используем функцию в запросе
4. Неправильная статистика
	- Решение
		- Использовать хинты
		- Использовать фильтрованную статистику
5. Временные таблицы/табличные переменные
	- Для табличной переменной оптимизатор не создаёт статистику вообще
	- Создаёт статистику для врменной таблицы
6. Выражение в предикате (действие над столбцом, на который делаем выборку (WHERE))
	- Не используется ни индекс, ни статистика
	- Решение
		- Не использовать такое выражание
		- Вычисляемый столбец для этого выражения
7. Если есть кореляция (2 столбца, которые сильно различаются по количеству уникальных значений)
	- Решение
		- Построить фильтрованный индекс
8. Read-only Databases и Read-Only Databases Snapshot
	- Статистика не может быть создана, потому что её некуда записывать, но в SQL SErver 2012 есть место куда мы можем
	записать статистику - tempdb. Минусы такого подхода:
		1. Только автоматическая статистика;
		2. При перезагрузке сервера она исчезает
	
-- Выбор неэффективного плана запроса или оценка кардинальности
- Оценка кардинальности (Cardinality Estimation в плане выполнения запроса) - количество строк, которое ожидается
  на выходе конкретного оператора в плане запроса. Основные данные для этого - статистика.
- Зачем нужна оценка кардинальности
	1. Стоимость запроса складывается из стоимостей операторов
	2. Стоимость оператора основывается на объём необходимых вычислений, требуемо памяти и ввода-вывода
	3. Объём данных - важнейший параметр в данной форме. Это и есть Оценка Кардинальности
- Оценка использования
	1. Оценка стоимости плана
	2. Оценка гранта памяти. Если неправильно оценим, то выделится меньше памяти для запроса и он будет медленным
	3. Влияние на некоторые эвриситики при выборе плана запроса
	4. Влияние на выбор статегии блокировки
- Как SQL оценивает кардинальность
	1. Статистика (гистограмма, плотность)
	2. Когда нет статистики, SQL применяет догадки
	
-- Посмотреть статистику можно через
SELECT * FROM sys.objects  inner join sys.stats  ON sys.objects.object_id = sys.stats.object_id

-- Посмотреть статистику
	DBCC SHOW_STATISTICS (Films2,_WA_Sys_00000005_113584D1)
	DBCC SHOW_STATISTICS (Films2,_WA_Sys_00000005_113584D1) WITH HISTOGRAM -- посмотреть только гистограмму

-- По умолчанию статистика создаётся по выборочному чтению

-- Посмотреть актуальный план запроса
SET STATISTICS xml ON

-- Как сравнивать оценочное количество строк с реальными
Actual Number Of Rows = Estimated Number Of Rows * Estimated number of Execution

-- Проблемы
	1. Табличная функция. Сервер не знает какая работа будет проводиться в функции, поэтому не может нормально оценить.
		- Решение - Переписать запрос с использованием временной таблицей
	2. Начинаем использовать tempdb для выгрузки промежуточных результатов
	3. План используется Nested Loop Join и оценка количества строк внешней стороны существенно меньше относительно
	   реального количества строк
	4. План использует Scan, который обрабатывает намного больше строк, по сравнению с оценкой
	5. Количество требуемых строк переоценено и мы решаем использовать Scan, хотя в реальности план с Seek Был бы быстрее
	6. План выполняет слишком много случаных Seek
	7. Из-за недооценки кардинальности запрос не выделяет достаточно количества памяти и при выполнении соответсвующий
	   оператор использует tempdb
-- Не обязательно проблемы
	1. Точная оценка бывает редко, чаще лоя простых предикатов и ближе к листовым частям плана. Небольшие неточности в
	   обсолютном значении обычно не выывают проблем, речь не идёт, например, об очень небольшом общем количестве строк
	   на внешней стороне Nested loop Join
	2. Иногда оценка количества строк на внешней стороне join уже сама по себе настолько велика, что вряд ли значение
	   такого количества строк позволило бы нам выбрать другой тип join
	3. Неточная оценка кардинальности на нижних уровнях плана растпрстраняется вверх. Ищите оператор, для которого
	   неточная	оценка может сильно влиять на производительность, прежде чем искать корень неточной оценки

-- Error log
	exec xp_readerrorlog 0,1, N'DBCC', N'3606','20120401','20120401 18:00'  -- Считывать данные из журнала. 0 - Какая строка из журнала,
                                                              -- 1 - какой журнал, следующие 2 параметра - фильтр, ещё 2 - дата с по
															  
	-- Более универсальная выборка
		CREATE TABLE #tt
		(
		d datetime ,
		proce nvarchar(255),
		t varchar(max)
		)

		INSERT INTO #tt
		exec sp_readerrorlog


		SELECT * FROM #tt WHERE t not like '%18456%' and t not like  '%RS-CASTSRV$%'
	   
-- Недокументированные возможности
1. DBCC (позволяет оперативно определить неисправности и найти проблемы связанная с производительностью)
DBCC TRACEON(2588) -- Список всех интсрукций DBCC
DBCC HELP('?') -- Список документированных интсрукций DBCC
DBCC AUTOPILOT
DBCC DBINFO WITH TABLERESULTS; -- Информация о текущей бд (реальное время создание базы)
DBCC DBREINDEX -- Перестроение всех индексов таблицы
DBCC DBREINDEXALL ('DBName') -- Перестроить все индексы базы
DBCC FREEPROCCACHE WITH NO_INFOMSGS; -- Сбросить весь кэш планов
DBCC FREEPROCCACHE(0x05000F006FB9565D40615615050000000000000000000000) -- сбросить кэш определённого плана (plan_handle)
DBCC FLUSHPROCINDB (5) -- Сбросить кэш планов конкретной базы(в скобках номер базы данных)
DBCC DROPCLEANBUFFERS -- Удаляет все чистые буферы из буферного пула. Перед выполнением запустить CHECKPOINT в каждой БД
DBCC LOG (5) -- Чтение информации из лога базы данных

2. Процедуры и функции
exec sp_MSforeachdb 'print [?]' -- Пройтись курсором по всем БД и выполнить какие-то команды в рамках объектов
	exec sp_MSforeachdb 'USE [?] SELECT * FROM [sys].[openkeys]'

exec sp_MSforeachtable 'pring "?"'-- Пройтись курсором по всем пользовательским таблицам и выполнить какие-то команды в рамках объектов
exec sp_MSforeachtable 'SELECT * FROM ?'
exec sp_MS_marksystemobject 'DbName' -- Позволяет объект сделать системным в базу master
exec xp_enumerrorlogs 2 -- Работать с журналом ошибок. 1 - Журнал сервера, 2 - Журнал Agent

exec sp_MSindexspace 'DBName' -- Размер индексов конкретной таблицы
exec xp_dirtree 'c:\temp',0,1	-- Работа с файлами(просмотр). Первое - дирректория, второе - вложенность, третье - выводить ли нам по файлам	
exec xp_fileexist 'c:\temp\test.txt' -- Существование файлов в файловой системе							
exec xp_fixeddrivers -- Свободное место на дисках в мегобайтах

exec sp_columns_100 'TableName' -- Информация о колонках какой-то таблицы
exec sp_tablecollations_100 'TableName' -- Информация о коллейшенах

select * from fn_dblog (default,default) -- Работа с журналом транзакций
select @@MICROSOFTVERSION / 0x1000000 -- Вкрсия SQL сервера

select PWDENCRYPT ('ffff') -- Получить хэш строки
pwdcompare ('MyHashPassword', password) -- Сравнение хэшей. password - hash из таблицы

SELECT indexproperty(object_id('dbo.Banners'),'PK_Banners','IndexFillFactor') -- Возвращает значение свойства указанного индекса

3. Подскаки
QUERYTRACEON -- Вкл трассировочные флаги на уровне опредлённого запроса (SELECT x FROM correlated WHERE f1 = 0 and f2 = 1 OPTION (QUERYTRACEON 4199))

4. DMV
select * from master..syscursorcolumns; -- Хранить список столбцов курсора
select * from master..syscursorrefs;  -- Хранит по одной записи на каждый серверный курсор 
select * from master..syscursors; --Хранит свойства серверного курсора
select * from master..syscursortables; --Хранит базовые таблицы серверного курсора
select * from sys.dm_exec_query_transformation_stats; --Правила которые использует оптимизатор (DBCC RULEOFF/RULEON, DBCC RULEON('GetToIdxScan');)

5. Псевдо столбцы
- не храняться в таблице, но можно с ними работать
select %%physloc%% as physloc, sys.fn_PhysLocFormatter( %%physloc%% ), * from dbo.Employees t; -- Узнать где находится каждая запись на уровне
                                                                                               -- страниц, найти страницу можно через DBCC PAGE
- Определить какая строка сейчас заброкирована     
	- Внутри транзакции можно посмотреть какие блокировки наложены 
		select * from sys.dm_tran_locks where request_session_id = @@spid;
	- и по полю resource_description можно определить какая строка находится в блокировке. Значение эого поля сравнить со значение первого
	столбца, так мы найдём заблокированную строку
		select %%lockres%% as lockres, * from dbo.Employees;
		select * from dbo.Employees where %%lockres%% in ( '(61a06abd401c)' );
		
6. Процедуры
sp_MSforeachtable @command1="print '?' dbcc checktable ('?')" -- Перебор всех таблиц базы и применение к ним команд
															  -- Поддерживается до 3-х команд (@command1, @command1 и @command3)
		
7. Стартовые параметры
- -q "collation" -- указать коллейшн для системных баз

-- Повлиять на запрос
	- Hint
	- OPTION, можно указать какие типы соединений SQL Server может использовать
	- Скобки 
		SELECT * FROM t1 INNER JOIN (t2 INNER JOIN t3 ON t2.id=t3.id) ON t1.id=t2.id 
	- Force order (соединять в том порядке, в котором написано)
		OPTION (force order)
	- Чтобы указать какой тип соединения использовать нужно добавить к JOIN название физического соединения INNER JOIN >> INNER LOOP JOIN

-- Spool/Table Spool
	- Сброс данных в tempdb или сортировка там
	- Сортирует данные в памяти
	- Если функция не возвращает данные, то используйте WITH SCHEMABINDING, чтобы избежать Table Spool
	
-- SpillLevel (Order BY)/ spill to tempdb/Spills
	- Недостаточно памяти для Sort и Hash операторов
	- Сброс на диск (tempdb) и расчитывание там, вместо памяти
	- Если varchar(100) оптимизатор считает что это varchar(50). Определять лучше в 2 раза больше, чем есть на самом деле
	- Причины
		1. Плохая статистика
		2. Неправильная оценка размера строки
	- Как обнаружить
		- В Profiler - sort warnings
		- Extended Event – “sort_warning”
		- Use PerfMom or sys.dm_os_performance to track “worktables created/sec” and “workfiles created/sec”
	- Как решить проблему
		- Избавиться от сортировки
		- Использовать TOP
		- Не использовать в сортировке ненужные столбцы
		- Не использовать большие по размеру столбцы
		- Используйте OPTION (Recompile), особенно если используем локальные переменные
		- Если сравниваются 2 колонки, то для эффективной работы надо либо создавать вычисляемый столбец, либо делать статистику по ним (точ в точ, как будет выглядеть сравнение)
		- Определять размер столбцов в 2 разра больше, чем реальные данные, так как сервер при оптимизации выделяет памяти в половину varchar. То есть для varchar(100) он выделит как для varchar(50)
			
-- Read-Ahead (Упреждающее чтение)
	- Компонент Database Engine поддерживает механизм оптимизации производительности, называемый упреждающим чтением. Он заключается в том, что система пытается предугадать, какие именно страницы данных и индексов понадобятся для плана выполнения запроса, и помещает эти страницы в буферный кэш, прежде, чем в них возникнет реальная необходимость. Это позволяет распараллелить операции вычисления и ввода-вывода, полностью задействовав процессорные и дисковые мощности.
	- Упреждающее чтение бывает двух видов: для страниц данных и для страниц индексов.
	
-- Количество файлов базы данных/number of database data files
	- As a general rule of thumb, I recommend each filegroup having 2-4 data files, as this will give overall better I/O performance than a single data file
	- As your databases get larger, it becomes more likely that you’re going to need multiple files and filegroups
	- Multiple filegroups give you enhanced possibilities for targeted disaster recovery, easier manageability, and I/O subsystem placement
		
-- Параллелизм/parallelism
	- Критерии параллелизма		
		1. Работает ли SQL Server на компьютере, имеющем более одного микропроцессора или ЦП (таком как симметричный многопроцессорный компьютер (SMP)).
			Использовать параллельные запросы могут только компьютеры, имеющие более одного ЦП.
		2. Достаточно ли доступных потоков.
			Каждый запрос или операция с индексами требуют определенного числа потоков, подлежащих выполнению. Для выполнения параллельного плана требуется больше потоков, чем для выполнения последовательного плана, и число запрашиваемых потоков возрастает по мере увеличения степени параллелизма. Когда требование к потокам параллельного плана для определенной степени параллелизма не может быть удовлетворено, компонент Database Engine уменьшает степень параллелизма автоматически или полностью отказывается от параллельного плана в указанном контексте рабочей нагрузки. В таком случае начинается выполнение последовательного плана (один поток).
		3. Тип выполняемого запроса или операции с индексами.
			Операции с индексами, которые создают или перестраивают индекс или удаляют кластеризованный индекс и запросы, интенсивно использующие циклы ЦП, являются лучшими кандидатами для параллельного плана. Например, хорошими кандидатами являются соединения больших таблиц, больших статистических выражений и сортировка больших результирующих наборов. Простые запросы, часто находящиеся в приложениях обработки транзакций, находят дополнительную координацию, запрашиваемую для выполнения запроса в параллельном перевешивании возможного повышения производительности. Чтобы отличить запросы, которые выигрывают от параллелизма, и запросы, которые не выигрывают, компонент Database Engine сравнивает предполагаемую стоимость выполняемого запроса или операции с индексами со значением cost threshold for parallelism. Несмотря на то, что это не рекомендуется, пользователи могут менять значение по умолчанию 5 при помощи процедуры sp_configure.
		4. Достаточно ли число строк, подлежащих обработке.
			Если оптимизатор запросов устанавливает, что число строк слишком мало, то для распространения строк он не вставляет операторы преобразования валюты. Следовательно, операторы обрабатываются последовательно. Обработка операторов в последовательном плане позволяет избежать сценариев, когда стоимость запуска, распределения и координации превышает преимущества, достигнутые параллельной обработкой оператора.
		5. Доступна ли статистика распределения.
			Если наивысшая степень параллелизма невозможна, более низкие степени рассматриваются до того, как отвергается параллельный план.
			Например, статистика распределения не может вычисляться при создании кластеризованного индекса на представлении, потому что кластеризованный индекс еще не существует. В таком случае компонент Database Engine не может предоставить наивысшую степень параллелизма для операции с индексами. Однако некоторые операторы, такие как сортировка и сканирование, по-прежнему могут выигрывать от параллельной обработки.
			
-- SET ANSI_PADDING 
	- Мы рекомендуем всегда устанавливать для параметра ANSI_PADDING значение ON.
	- Контролирует способ хранения в столбце значений короче, чем определенный размер столбца, и способ хранения в столбце значений, имеющих замыкающие пробелы, в данных char, varchar, binary и varbinary.
	
-- SET QUOTED_IDENTIFIER 
	Заставляет SQL Server следовать правилам ISO относительно разделения кавычками идентификаторов и строк-литералов. Идентификаторы, заключенные в двойные кавычки, могут быть либо зарезервированными ключевыми словами Transact-SQL, либо могут содержать символы, которые обычно запрещены правилами синтаксиса для идентификаторов Transact-SQL.
	
-- SET ANSI_NULLS 
	- Мы рекомендуем всегда устанавливать для параметра ANSI_PADDING значение ON.
	- Задает совместимое со стандартом ISO поведение операторов сравнения «равно» (=) и «не равно» (<>) при использовании со значениями NULL.

-- Доступ к системным таблицам
	- Подключиться под ADMIN
	- sp_helptext 'sys.tables'
	- SELECT Из корневой таблицы
	- SELECT OBJECT_DEFINITION(OBJECT_ID('sys.objects$'))
	
-- Active Directory
	- найти группу или пользователей
		rundll32 dsquery, OpenQueryWindow	
	- в какую группу входит пользователь
		net user DKX6AO0ADM /domain
		
-- Дополнительные логи при установке/удалении
		C:\Program Files\Microsoft SQL Server\90\Setup Bootstrap\LOG